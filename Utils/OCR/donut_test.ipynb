{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline,DonutProcessor, VisionTextDualEncoderProcessor\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the encoder: <class 'transformers.models.donut.modeling_donut_swin.DonutSwinModel'> is overwritten by shared encoder config: DonutSwinConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"depths\": [\n",
      "    2,\n",
      "    2,\n",
      "    14,\n",
      "    2\n",
      "  ],\n",
      "  \"drop_path_rate\": 0.1,\n",
      "  \"embed_dim\": 128,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"image_size\": [\n",
      "    2560,\n",
      "    1920\n",
      "  ],\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"mlp_ratio\": 4.0,\n",
      "  \"model_type\": \"donut-swin\",\n",
      "  \"num_channels\": 3,\n",
      "  \"num_heads\": [\n",
      "    4,\n",
      "    8,\n",
      "    16,\n",
      "    32\n",
      "  ],\n",
      "  \"num_layers\": 4,\n",
      "  \"patch_size\": 4,\n",
      "  \"path_norm\": true,\n",
      "  \"qkv_bias\": true,\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"use_absolute_embeddings\": false,\n",
      "  \"window_size\": 10\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.mbart.modeling_mbart.MBartForCausalLM'> is overwritten by shared decoder config: MBartConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 4,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"max_position_embeddings\": 128,\n",
      "  \"model_type\": \"mbart\",\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": true,\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 57532\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지에서 추출된 텍스트:\n",
      "p p p p p p p p p p p p p p p p p p p p p n o o . 6\n"
     ]
    }
   ],
   "source": [
    "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
    "from PIL import Image\n",
    "\n",
    "# Donut 모델과 프로세서 불러오기\n",
    "model_name = \"naver-clova-ix/donut-base-finetuned-docvqa\"\n",
    "processor = DonutProcessor.from_pretrained(model_name)\n",
    "model = VisionEncoderDecoderModel.from_pretrained(model_name)\n",
    "\n",
    "# 이미지 파일 경로\n",
    "image_path = \"C:/Users/82107/Desktop/kst_pipeline/Utils/OCR/P3_1_01_21114_49495.png\"\n",
    "\n",
    "# 이미지 열기 및 RGB로 변환\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "# 모델 입력 전처리\n",
    "pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "\n",
    "# 디코더 시작 토큰 준비\n",
    "decoder_input_ids = processor.tokenizer(\"<s>\", add_special_tokens=False, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# 모델 추론\n",
    "outputs = model.generate(pixel_values, decoder_input_ids=decoder_input_ids, max_length=512)\n",
    "\n",
    "# 텍스트 디코딩\n",
    "extracted_text = processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "\n",
    "# 결과 출력\n",
    "print(\"이미지에서 추출된 텍스트:\")\n",
    "print(extracted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=598x105 at 0x1B692DB9B50>\n"
     ]
    }
   ],
   "source": [
    "image_path = \"C:/Users/82107/Desktop/kst_pipeline/Utils/OCR/P3_1_01_21114_49495.png\"\n",
    "\n",
    "image = Image.open(image_path)\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\82107\\.cache\\huggingface\\hub\\models--microsoft--trocr-base-handwritten. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"image_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": false,\n",
      "  \"transformers_version\": \"4.46.3\"\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"cross_attention_hidden_size\": 768,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layernorm_embedding\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"trocr\",\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"use_cache\": false,\n",
      "  \"use_learned_position_embeddings\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages\\transformers\\generation\\utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추출된 텍스트:\n",
      "# 3/ MAN. 813 S. 4/7B. 1/2 3.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from PIL import Image\n",
    "\n",
    "# 1. TrOCR 모델 및 프로세서 로드\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "\n",
    "# 2. 이미지 경로 지정\n",
    "image_path = \"C:/Users/82107/Desktop/kst_pipeline/Utils/OCR/P3_1_01_21114_49495.png\"  # 테스트할 이미지 파일 경로\n",
    "\n",
    "# 3. 이미지 열기\n",
    "image = Image.open(image_path).convert(\"RGB\")  # RGB로 변환 (필수)\n",
    "\n",
    "# 4. 이미지 전처리 및 모델 입력\n",
    "pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "\n",
    "# 5. 텍스트 예측\n",
    "outputs = model.generate(pixel_values)\n",
    "\n",
    "# 6. 추출된 텍스트 디코딩\n",
    "predicted_text = processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "\n",
    "# 7. 결과 출력\n",
    "print(\"추출된 텍스트:\")\n",
    "print(predicted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"image_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": false,\n",
      "  \"transformers_version\": \"4.46.3\"\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"cross_attention_hidden_size\": 768,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layernorm_embedding\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"trocr\",\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"use_cache\": false,\n",
      "  \"use_learned_position_embeddings\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR 텍스트: the church was built in the Cottagas Mississippi neighborhood of the U.Cottag\n",
      "이미지 캡션: the korean language is displayed on a computer screen\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel, BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "\n",
    "# TrOCR 로드\n",
    "trocr_processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "trocr_model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "\n",
    "# BLIP 로드\n",
    "blip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "# OCR 텍스트 추출 함수\n",
    "def extract_text(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    pixel_values = trocr_processor(image, return_tensors=\"pt\").pixel_values\n",
    "    generated_ids = trocr_model.generate(pixel_values)\n",
    "    text = trocr_processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return text\n",
    "\n",
    "# BLIP 캡셔닝 생성 함수\n",
    "def generate_caption(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = blip_processor(image, return_tensors=\"pt\")\n",
    "    outputs = blip_model.generate(**inputs)\n",
    "    caption = blip_processor.decode(outputs[0], skip_special_tokens=True)\n",
    "    return caption\n",
    "\n",
    "# 실행\n",
    "image_path = \"C:/Users/82107/Desktop/kst_pipeline/Utils/OCR/P3_1_01_23205_63962.png\"\n",
    "ocr_text = extract_text(image_path)\n",
    "caption = generate_caption(image_path)\n",
    "\n",
    "print(\"OCR 텍스트:\", ocr_text)\n",
    "print(\"이미지 캡션:\", caption)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting paddleocr\n",
      "  Downloading paddleocr-2.9.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting shapely (from paddleocr)\n",
      "  Downloading shapely-2.0.6-cp39-cp39-win_amd64.whl.metadata (7.2 kB)\n",
      "Collecting scikit-image (from paddleocr)\n",
      "  Downloading scikit_image-0.24.0-cp39-cp39-win_amd64.whl.metadata (14 kB)\n",
      "Collecting imgaug (from paddleocr)\n",
      "  Downloading imgaug-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pyclipper (from paddleocr)\n",
      "  Downloading pyclipper-1.3.0.post6-cp39-cp39-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting lmdb (from paddleocr)\n",
      "  Downloading lmdb-1.5.1-cp39-cp39-win_amd64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from paddleocr) (4.67.1)\n",
      "Collecting numpy<2.0 (from paddleocr)\n",
      "  Downloading numpy-1.26.4-cp39-cp39-win_amd64.whl.metadata (61 kB)\n",
      "Collecting rapidfuzz (from paddleocr)\n",
      "  Downloading rapidfuzz-3.10.1-cp39-cp39-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from paddleocr) (4.10.0.84)\n",
      "Collecting opencv-contrib-python (from paddleocr)\n",
      "  Downloading opencv_contrib_python-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting cython (from paddleocr)\n",
      "  Downloading Cython-3.0.11-cp39-cp39-win_amd64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: Pillow in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from paddleocr) (11.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from paddleocr) (6.0.2)\n",
      "Collecting python-docx (from paddleocr)\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from paddleocr) (4.12.3)\n",
      "Requirement already satisfied: fonttools>=4.24.0 in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from paddleocr) (4.55.1)\n",
      "Collecting fire>=0.3.0 (from paddleocr)\n",
      "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: requests in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from paddleocr) (2.32.3)\n",
      "Collecting albumentations==1.4.10 (from paddleocr)\n",
      "  Downloading albumentations-1.4.10-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting albucore==0.0.13 (from paddleocr)\n",
      "  Downloading albucore-0.0.13-py3-none-any.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: tomli>=2.0.1 in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from albucore==0.0.13->paddleocr) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from albucore==0.0.13->paddleocr) (4.12.2)\n",
      "Collecting opencv-python-headless>=4.9.0.80 (from albucore==0.0.13->paddleocr)\n",
      "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from albumentations==1.4.10->paddleocr) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.3.2 in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from albumentations==1.4.10->paddleocr) (1.5.2)\n",
      "Requirement already satisfied: pydantic>=2.7.0 in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from albumentations==1.4.10->paddleocr) (2.10.2)\n",
      "Collecting termcolor (from fire>=0.3.0->paddleocr)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from scikit-image->paddleocr) (3.2.1)\n",
      "Collecting imageio>=2.33 (from scikit-image->paddleocr)\n",
      "  Downloading imageio-2.36.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image->paddleocr)\n",
      "  Downloading tifffile-2024.8.30-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from scikit-image->paddleocr) (24.2)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image->paddleocr)\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from beautifulsoup4->paddleocr) (2.6)\n",
      "Requirement already satisfied: six in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from imgaug->paddleocr) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from imgaug->paddleocr) (3.9.3)\n",
      "Collecting lxml>=3.1.0 (from python-docx->paddleocr)\n",
      "  Downloading lxml-5.3.0-cp39-cp39-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from requests->paddleocr) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from requests->paddleocr) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from requests->paddleocr) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from requests->paddleocr) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from tqdm->paddleocr) (0.4.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from pydantic>=2.7.0->albumentations==1.4.10->paddleocr) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from pydantic>=2.7.0->albumentations==1.4.10->paddleocr) (2.27.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from scikit-learn>=1.3.2->albumentations==1.4.10->paddleocr) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from scikit-learn>=1.3.2->albumentations==1.4.10->paddleocr) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from matplotlib->imgaug->paddleocr) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from matplotlib->imgaug->paddleocr) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from matplotlib->imgaug->paddleocr) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from matplotlib->imgaug->paddleocr) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from matplotlib->imgaug->paddleocr) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from matplotlib->imgaug->paddleocr) (6.4.5)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\82107\\anaconda3\\envs\\kst_pp\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->imgaug->paddleocr) (3.21.0)\n",
      "Downloading paddleocr-2.9.1-py3-none-any.whl (544 kB)\n",
      "   ---------------------------------------- 0.0/544.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 544.7/544.7 kB 9.1 MB/s eta 0:00:00\n",
      "Downloading albucore-0.0.13-py3-none-any.whl (8.5 kB)\n",
      "Downloading albumentations-1.4.10-py3-none-any.whl (161 kB)\n",
      "Downloading numpy-1.26.4-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 4.5/15.8 MB 20.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 8.9/15.8 MB 20.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.8/15.8 MB 20.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 18.4 MB/s eta 0:00:00\n",
      "Downloading scikit_image-0.24.0-cp39-cp39-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 4.2/12.9 MB 20.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.2/12.9 MB 22.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 21.8 MB/s eta 0:00:00\n",
      "Downloading Cython-3.0.11-cp39-cp39-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.8/2.8 MB 18.0 MB/s eta 0:00:00\n",
      "Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
      "   ---------------------------------------- 0.0/948.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 948.0/948.0 kB 14.6 MB/s eta 0:00:00\n",
      "Downloading lmdb-1.5.1-cp39-cp39-win_amd64.whl (105 kB)\n",
      "Downloading opencv_contrib_python-4.10.0.84-cp37-abi3-win_amd64.whl (45.5 MB)\n",
      "   ---------------------------------------- 0.0/45.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.6/45.5 MB 7.6 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 5.2/45.5 MB 13.3 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 8.9/45.5 MB 14.6 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 13.1/45.5 MB 15.5 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 17.0/45.5 MB 16.0 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 21.0/45.5 MB 16.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 24.6/45.5 MB 16.8 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 29.4/45.5 MB 17.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 33.8/45.5 MB 17.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 37.5/45.5 MB 17.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.7/45.5 MB 18.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 43.5/45.5 MB 17.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 43.8/45.5 MB 16.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.0/45.5 MB 15.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.3/45.5 MB 14.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.3/45.5 MB 14.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.3/45.5 MB 14.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 45.5/45.5 MB 12.0 MB/s eta 0:00:00\n",
      "Downloading pyclipper-1.3.0.post6-cp39-cp39-win_amd64.whl (110 kB)\n",
      "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "Downloading rapidfuzz-3.10.1-cp39-cp39-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 14.3 MB/s eta 0:00:00\n",
      "Downloading shapely-2.0.6-cp39-cp39-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/1.4 MB 19.0 MB/s eta 0:00:00\n",
      "Downloading imageio-2.36.1-py3-none-any.whl (315 kB)\n",
      "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading lxml-5.3.0-cp39-cp39-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   -------------------------------------- - 3.7/3.8 MB 16.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 16.2 MB/s eta 0:00:00\n",
      "Downloading opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "   ---------------------------------------- 0.0/38.8 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 3.7/38.8 MB 19.8 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 7.6/38.8 MB 18.1 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 10.5/38.8 MB 16.8 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 14.2/38.8 MB 16.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 17.0/38.8 MB 17.0 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 21.0/38.8 MB 16.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 25.4/38.8 MB 17.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 29.1/38.8 MB 17.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 33.0/38.8 MB 17.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.4/38.8 MB 16.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.3/38.8 MB 16.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.8/38.8 MB 16.0 MB/s eta 0:00:00\n",
      "Downloading tifffile-2024.8.30-py3-none-any.whl (227 kB)\n",
      "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Building wheels for collected packages: fire\n",
      "  Building wheel for fire (setup.py): started\n",
      "  Building wheel for fire (setup.py): finished with status 'done'\n",
      "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114262 sha256=8c640fd5c9c0ab911efc1031dd8ff1b885fa6a1732f0d315b92ba77f0da2e523\n",
      "  Stored in directory: c:\\users\\82107\\appdata\\local\\pip\\cache\\wheels\\3b\\ee\\ac\\319a7b7f331f61050d0d54425079b2a883b445be3c7284a4eb\n",
      "Successfully built fire\n",
      "Installing collected packages: pyclipper, lmdb, termcolor, rapidfuzz, numpy, lxml, lazy-loader, cython, tifffile, shapely, python-docx, opencv-python-headless, opencv-contrib-python, imageio, fire, scikit-image, albucore, imgaug, albumentations, paddleocr\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\82107\\anaconda3\\envs\\kst_pp\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\82107\\anaconda3\\envs\\kst_pp\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] 액세스가 거부되었습니다: 'C:\\\\Users\\\\82107\\\\anaconda3\\\\envs\\\\kst_pp\\\\Lib\\\\site-packages\\\\cv2\\\\cv2.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install paddleocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'paddleocr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpaddleocr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PaddleOCR\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_text_with_paddleocr\u001b[39m(image_path):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'paddleocr'"
     ]
    }
   ],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "from PIL import Image\n",
    "\n",
    "def extract_text_with_paddleocr(image_path):\n",
    "    ocr = PaddleOCR(lang='korean')  # 한글 지원\n",
    "    result = ocr.ocr(image_path)\n",
    "    text = ' '.join([line[1][0] for line in result[0]])\n",
    "    return text\n",
    "\n",
    "# 예제 실행\n",
    "image_path = \"C:/Users/82107/Desktop/kst_pipeline/Utils/OCR/P3_1_01_23205_63962.png\"\n",
    "ocr_text = extract_text_with_paddleocr(image_path)\n",
    "print(\"OCR 결과:\", ocr_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "\n",
    "def generate_caption(image_path):\n",
    "    processor = BlipProcessor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "    model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "    \n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    out = model.generate(**inputs)\n",
    "    caption = processor.decode(out[0], skip_special_tokens=True)\n",
    "    return caption\n",
    "\n",
    "# 예제 실행\n",
    "caption = generate_caption(image_path)\n",
    "print(\"이미지 캡션:\", caption)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kst_pp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
