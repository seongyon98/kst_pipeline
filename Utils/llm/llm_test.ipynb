{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from neo4j import GraphDatabase\n",
    "import torch\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "import json\n",
    "from langchain import LLMChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM을 사용한 수학 키워드 및 대분류 추출 함수\n",
    "def extract_keywords_and_category_from_math_problem(text):\n",
    "    prompt = (\n",
    "        \"다음 수학 문제에서 수학과 직접적으로 관련된 키워드와 가장 적합한 대분류를 추출하세요. \"\n",
    "        \"키워드는 '키워드:'로 시작하고 대분류는 '대분류:'로 시작하여 각각 추출해주세요. \"\n",
    "        \"대분류는 '변화와 관계', '도형과 측정', '자료와 가능성' 중에서 하나를 먼저 확인하고, \"\n",
    "        \"그래프나 표와 관련된 문제는 우선적으로 '자료와 가능성'으로 분류하고, \"\n",
    "        \"길이, 넓이, 들이, 무게 등의 단위 관련 문제는 '도형과 측정'으로 분류하며, \"\n",
    "        \"배열, 규칙, 비율과 관련된 문제는 '변화와 관계'로 분류하세요. \"\n",
    "        \"어디에도 속하지 않으면 '수와 연산'으로 분류하세요.\\n\"\n",
    "        f\"문제: {text}\"\n",
    "    )\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        max_tokens=150,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"].strip()\n",
    "\n",
    "\n",
    "# 키워드 전처리 함수\n",
    "def preprocess_keywords(raw_keywords):\n",
    "    # 키워드 부분만 추출\n",
    "    keywords = raw_keywords.split(\"키워드:\")[1].strip().split(\", \")\n",
    "    # 각 키워드를 소문자로 변환하여 리스트로 반환\n",
    "    return [kw.lower() for kw in keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드 고정\n",
    "def set_seed(seed=12345):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "# 시드 고정 설정\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(keywords, leaf):\n",
    "    \"\"\"\n",
    "    키워드와 리프 간의 유사도를 계산하는 함수 (GraphRAG)\n",
    "    :param keywords: 키워드 리스트\n",
    "    :param leaf: 리프 노드 이름\n",
    "    :return: 유사도 값\n",
    "    \"\"\"\n",
    "    query_keywords = \" \".join(keywords)\n",
    "    query_text = f\"Calculate similarity between {query_keywords} and {leaf}\"\n",
    "\n",
    "    # GraphRAG를 통해 유사도 계산\n",
    "    response = rag.search(query_text=query_text, retriever_config={\"top_k\": 1})\n",
    "    similarity_score = response.answer[0].get(\"similarity\", 0.0)\n",
    "\n",
    "    return similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_nodes_from_graph(keywords, category, level, similarity_threshold=0.8):\n",
    "    # GraphRAG를 사용하여 유사도 검색\n",
    "    query_text = f\"Find nodes related to {', '.join(keywords)} in category {category} at level {level}\"\n",
    "    print(f\"Query Text: {query_text}\")\n",
    "\n",
    "    try:\n",
    "        response = rag.search(query_text=query_text, retriever_config={\"top_k\": 5})\n",
    "        print(f\"Response Type: {type(response)}\")\n",
    "        print(f\"Raw Response: {response}\")\n",
    "\n",
    "        # JSON 파싱 시도\n",
    "        if isinstance(response, str):\n",
    "            response_data = json.loads(response)\n",
    "        else:\n",
    "            response_data = response  # JSON 객체라면 그대로 사용\n",
    "\n",
    "        # 유사도 필터링\n",
    "        if \"answer\" in response_data:\n",
    "            matched_nodes = [\n",
    "                node\n",
    "                for node in response_data[\"answer\"]\n",
    "                if node.get(\"similarity\", 0) >= similarity_threshold\n",
    "            ]\n",
    "            print(f\"Matched Nodes: {matched_nodes}\")\n",
    "            return [node[\"name\"] for node in matched_nodes]\n",
    "        else:\n",
    "            print(\"No 'answer' field in response data.\")\n",
    "            return []\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSONDecodeError: {e}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_subcategories(keywords, category):\n",
    "    best_match = find_similar_nodes_from_graph(keywords, category, level=\"Subcategory\")\n",
    "    if best_match:\n",
    "        return best_match\n",
    "    print(f\"중분류를 찾을 수 없습니다. 대분류: {category}\")\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_leaf_nodes(keywords, category_name, similarity_threshold=0.8):\n",
    "    subcategories = find_subcategories(keywords, category_name)\n",
    "    if not subcategories:\n",
    "        print(f\"중분류를 찾을 수 없습니다. 대분류: {category_name}\")\n",
    "        return []\n",
    "\n",
    "    leaf_nodes = []\n",
    "    for subcategory in subcategories:\n",
    "        print(f\"중분류 '{subcategory}'에서 하위 노드 탐색 시작\")\n",
    "        items = find_similar_nodes_from_graph(\n",
    "            keywords,\n",
    "            subcategory,\n",
    "            level=\"Item\",\n",
    "            similarity_threshold=similarity_threshold,\n",
    "        )\n",
    "        if not items:\n",
    "            print(f\"중분류 '{subcategory}'에 연결된 item이 없습니다.\")\n",
    "            continue\n",
    "        print(f\"중분류 '{subcategory}'에 연결된 item: {items}\")\n",
    "\n",
    "        for item in items:\n",
    "            query = \"\"\"\n",
    "                MATCH (i:Item {name: $item})-[:HAS_CHILD]->(ln:Leaf)\n",
    "                RETURN ln.name AS leaf\n",
    "            \"\"\"\n",
    "            with driver.session() as session:\n",
    "                result = session.run(query, item=item)\n",
    "                leaf_candidates = [record[\"leaf\"] for record in result]\n",
    "\n",
    "            for leaf in leaf_candidates:\n",
    "                leaf_similarity = calculate_similarity(keywords, leaf)\n",
    "                if leaf_similarity >= similarity_threshold:\n",
    "                    print(\n",
    "                        f\"최하위 노드 '{leaf}'는 유사도 {leaf_similarity:.2f}로 선택됨\"\n",
    "                    )\n",
    "                    leaf_nodes.append(leaf)\n",
    "                else:\n",
    "                    print(\n",
    "                        f\"최하위 노드 '{leaf}'는 유사도 {leaf_similarity:.2f}로 선택되지 않음\"\n",
    "                    )\n",
    "\n",
    "    return leaf_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_classification_with_llm(classification, keywords):\n",
    "    prompt = (\n",
    "        f\"다음 키워드: {', '.join(keywords)} 가 분류 '{classification}'에 정확히 적합한지 평가해주세요. \"\n",
    "        f\"해당 분류가 모든 {', '.join(keywords)} 와 직접적으로 연관되어야 합니다. 예를 들어, 다음과 같은 경우를 고려하세요:\"\n",
    "        \"키워드 '덧셈'이 분류 '곱셈'에 해당하는 경우 '부적합'으로 응답해야 하며, \"\n",
    "        \"키워드 '원뿔'이 분류 '직육면체'에 해당하는 경우 '부적합'으로 응답해야 합니다. \"\n",
    "        \"적합하지 않다면 '부적합'으로, 적합하다면 '적합'으로만 대답해주세요. \"\n",
    "    )\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        max_tokens=50,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "    result = response.choices[0].message[\"content\"].strip()\n",
    "    print(f\"LLM 응답: {result}\")  # 응답 메시지 출력 (디버깅용)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_math_problem(problem):\n",
    "    # 1단계: 키워드 및 대분류 추출\n",
    "    raw_keywords_and_category = extract_keywords_and_category_from_math_problem(problem)\n",
    "    print(f\"추출된 키워드 및 대분류 (원본): {raw_keywords_and_category}\")\n",
    "\n",
    "    # 키워드와 대분류 분리\n",
    "    try:\n",
    "        raw_keywords, most_similar_category = raw_keywords_and_category.split(\n",
    "            \"\\n대분류: \"\n",
    "        )\n",
    "    except ValueError:\n",
    "        print(\"응답 형식이 맞지 않습니다. 기본값으로 '수와 연산'을 사용합니다.\")\n",
    "        raw_keywords = raw_keywords_and_category\n",
    "        most_similar_category = \"수와 연산\"\n",
    "\n",
    "    keywords = preprocess_keywords(raw_keywords)\n",
    "    print(f\"전처리된 키워드: {keywords}\")\n",
    "    print(f\"가장 유사한 대분류: {most_similar_category}\")\n",
    "\n",
    "    # 2단계: 하위 노드 탐색\n",
    "    leaf_nodes = find_leaf_nodes(\n",
    "        keywords, most_similar_category, similarity_threshold=0.6\n",
    "    )\n",
    "    if not leaf_nodes:\n",
    "        print(\"하위 노드를 찾을 수 없습니다. 프로세스를 종료합니다.\")\n",
    "        return\n",
    "\n",
    "    print(f\"찾은 하위 노드: {leaf_nodes}\")\n",
    "\n",
    "    # 3단계: 최종 검증\n",
    "    verified_labels = []\n",
    "    for leaf in leaf_nodes:\n",
    "        verification = verify_classification_with_llm(leaf, keywords)\n",
    "        if verification == \"적합\":\n",
    "            verified_labels.append(leaf)\n",
    "\n",
    "    if verified_labels:\n",
    "        print(f\"최종 라벨: {verified_labels}\")\n",
    "    else:\n",
    "        print(\"적합한 라벨을 찾을 수 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Neo4j 드라이버 초기화 중...\n",
      "[INFO] Neo4j 연결 성공.\n",
      "추출된 키워드 및 대분류 (원본): 키워드: 기차, 사람, $1500$ 명, $80$ 명, $124$ 명\n",
      "대분류: 수와 연산\n",
      "전처리된 키워드: ['기차', '사람', '$1500$ 명', '$80$ 명', '$124$ 명']\n",
      "가장 유사한 대분류: 수와 연산\n",
      "Query Text: Find nodes related to 기차, 사람, $1500$ 명, $80$ 명, $124$ 명 in category 수와 연산 at level Subcategory\n",
      "[INFO] GraphRAG 검색 시작.\n",
      "[INFO] Query Embedding 생성 중: Find nodes related to 기차, 사람, $1500$ 명, $80$ 명, $124$ 명 in category 수와 연산 at level Subcategory\n",
      "[INFO] OpenAI Embedding 생성 요청: Find nodes related to 기차, 사람, $1500$ 명, $80$ 명, $124$ 명 in category 수와 연산 at level Subcategory\n",
      "[INFO] Embedding 생성 성공.\n",
      "[INFO] Cypher 쿼리 실행 중...\n",
      "[INFO] 쿼리 결과: []\n",
      "[INFO] 검색된 유사 항목: []\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 123\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# 문제 처리 실행\u001b[39;00m\n\u001b[0;32m    122\u001b[0m problem \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m기차에 사람이 $1500$ 명 타고 있었습니다. 이번 역에서 $80$ 명이 내리고 $124$ 명이 탔습니다. 지금 기차 안에 있는 사람은 모두 몇 명인지 구해 보세요.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 123\u001b[0m \u001b[43mprocess_math_problem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# Neo4j 드라이버 종료\u001b[39;00m\n\u001b[0;32m    126\u001b[0m driver\u001b[38;5;241m.\u001b[39mclose()\n",
      "Cell \u001b[1;32mIn[52], line 21\u001b[0m, in \u001b[0;36mprocess_math_problem\u001b[1;34m(problem)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m가장 유사한 대분류: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmost_similar_category\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# 2단계: 하위 노드 탐색\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m leaf_nodes \u001b[38;5;241m=\u001b[39m \u001b[43mfind_leaf_nodes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmost_similar_category\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msimilarity_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.6\u001b[39;49m\n\u001b[0;32m     23\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m leaf_nodes:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m하위 노드를 찾을 수 없습니다. 프로세스를 종료합니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[50], line 2\u001b[0m, in \u001b[0;36mfind_leaf_nodes\u001b[1;34m(keywords, category_name, similarity_threshold)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_leaf_nodes\u001b[39m(keywords, category_name, similarity_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     subcategories \u001b[38;5;241m=\u001b[39m \u001b[43mfind_subcategories\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategory_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m subcategories:\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m중분류를 찾을 수 없습니다. 대분류: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategory_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[49], line 2\u001b[0m, in \u001b[0;36mfind_subcategories\u001b[1;34m(keywords, category)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_subcategories\u001b[39m(keywords, category):\n\u001b[1;32m----> 2\u001b[0m     best_match \u001b[38;5;241m=\u001b[39m \u001b[43mfind_similar_nodes_from_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSubcategory\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m best_match:\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m best_match\n",
      "Cell \u001b[1;32mIn[48], line 7\u001b[0m, in \u001b[0;36mfind_similar_nodes_from_graph\u001b[1;34m(keywords, category, level, similarity_threshold)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery Text: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 7\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrag\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretriever_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_k\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse Type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(response)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaw Response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[53], line 111\u001b[0m, in \u001b[0;36mGraphRAG.search\u001b[1;34m(self, query_text, retriever_config)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] 검색된 유사 항목: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    110\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(r[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results])\n\u001b[1;32m--> 111\u001b[0m llm_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] LLM 응답 생성 성공.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m llm_response\n",
      "File \u001b[1;32mc:\\Users\\seong\\anaconda3\\envs\\kst_pp\\lib\\site-packages\\langchain\\chains\\base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[1;32mc:\\Users\\seong\\anaconda3\\envs\\kst_pp\\lib\\site-packages\\langchain\\chains\\base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[0;32m    167\u001b[0m     )\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\seong\\anaconda3\\envs\\kst_pp\\lib\\site-packages\\langchain\\chains\\llm.py:126\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    123\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m    124\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    125\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m--> 126\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\seong\\anaconda3\\envs\\kst_pp\\lib\\site-packages\\langchain\\chains\\llm.py:138\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[1;34m(self, input_list, run_manager)\u001b[0m\n\u001b[0;32m    136\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    139\u001b[0m         prompts,\n\u001b[0;32m    140\u001b[0m         stop,\n\u001b[0;32m    141\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs,\n\u001b[0;32m    143\u001b[0m     )\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[0;32m    146\u001b[0m         cast(List, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[0;32m    147\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\seong\\anaconda3\\envs\\kst_pp\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:786\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    780\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    784\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    785\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\seong\\anaconda3\\envs\\kst_pp\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:643\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    642\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    644\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    645\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    647\u001b[0m ]\n\u001b[0;32m    648\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32mc:\\Users\\seong\\anaconda3\\envs\\kst_pp\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:633\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 633\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    634\u001b[0m                 m,\n\u001b[0;32m    635\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    636\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    637\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    638\u001b[0m             )\n\u001b[0;32m    639\u001b[0m         )\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\seong\\anaconda3\\envs\\kst_pp\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:851\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 851\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    852\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    853\u001b[0m         )\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\seong\\anaconda3\\envs\\kst_pp\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py:291\u001b[0m, in \u001b[0;36mChatOllama._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate\u001b[39m(\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    269\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[0;32m    274\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call out to Ollama's generate endpoint.\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;124;03m            ])\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chat_stream_with_aggregation(\n\u001b[0;32m    292\u001b[0m         messages,\n\u001b[0;32m    293\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    294\u001b[0m         run_manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[0;32m    295\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    296\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[0;32m    298\u001b[0m     chat_generation \u001b[38;5;241m=\u001b[39m ChatGeneration(\n\u001b[0;32m    299\u001b[0m         message\u001b[38;5;241m=\u001b[39mAIMessage(content\u001b[38;5;241m=\u001b[39mfinal_chunk\u001b[38;5;241m.\u001b[39mtext),\n\u001b[0;32m    300\u001b[0m         generation_info\u001b[38;5;241m=\u001b[39mfinal_chunk\u001b[38;5;241m.\u001b[39mgeneration_info,\n\u001b[0;32m    301\u001b[0m     )\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatResult(generations\u001b[38;5;241m=\u001b[39m[chat_generation])\n",
      "File \u001b[1;32mc:\\Users\\seong\\anaconda3\\envs\\kst_pp\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py:222\u001b[0m, in \u001b[0;36mChatOllama._chat_stream_with_aggregation\u001b[1;34m(self, messages, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_chat_stream_with_aggregation\u001b[39m(\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    215\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    220\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatGenerationChunk:\n\u001b[0;32m    221\u001b[0m     final_chunk: Optional[ChatGenerationChunk] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m stream_resp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_stream(messages, stop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m stream_resp:\n\u001b[0;32m    224\u001b[0m             chunk \u001b[38;5;241m=\u001b[39m _chat_stream_response_to_chat_generation_chunk(stream_resp)\n",
      "File \u001b[1;32mc:\\Users\\seong\\anaconda3\\envs\\kst_pp\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py:194\u001b[0m, in \u001b[0;36mChatOllama._create_chat_stream\u001b[1;34m(self, messages, stop, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_chat_stream\u001b[39m(\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    186\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m    187\u001b[0m     stop: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    189\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    190\u001b[0m     payload \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_messages_to_ollama_messages(messages),\n\u001b[0;32m    193\u001b[0m     }\n\u001b[1;32m--> 194\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_stream(\n\u001b[0;32m    195\u001b[0m         payload\u001b[38;5;241m=\u001b[39mpayload, stop\u001b[38;5;241m=\u001b[39mstop, api_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/api/chat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    196\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\seong\\anaconda3\\envs\\kst_pp\\lib\\site-packages\\requests\\models.py:869\u001b[0m, in \u001b[0;36mResponse.iter_lines\u001b[1;34m(self, chunk_size, decode_unicode, delimiter)\u001b[0m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Iterates over the response data, one line at a time.  When\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;124;03mstream=True is set on the request, this avoids reading the\u001b[39;00m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;124;03mcontent at once into memory for large responses.\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \n\u001b[0;32m    864\u001b[0m \u001b[38;5;124;03m.. note:: This method is not reentrant safe.\u001b[39;00m\n\u001b[0;32m    865\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    867\u001b[0m pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 869\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_content(\n\u001b[0;32m    870\u001b[0m     chunk_size\u001b[38;5;241m=\u001b[39mchunk_size, decode_unicode\u001b[38;5;241m=\u001b[39mdecode_unicode\n\u001b[0;32m    871\u001b[0m ):\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pending \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    873\u001b[0m         chunk \u001b[38;5;241m=\u001b[39m pending \u001b[38;5;241m+\u001b[39m chunk\n",
      "File \u001b[1;32mc:\\Users\\seong\\anaconda3\\envs\\kst_pp\\lib\\site-packages\\requests\\utils.py:572\u001b[0m, in \u001b[0;36mstream_decode_response_unicode\u001b[1;34m(iterator, r)\u001b[0m\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    571\u001b[0m decoder \u001b[38;5;241m=\u001b[39m codecs\u001b[38;5;241m.\u001b[39mgetincrementaldecoder(r\u001b[38;5;241m.\u001b[39mencoding)(errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 572\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[0;32m    573\u001b[0m     rv \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(chunk)\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rv:\n",
      "File \u001b[1;32mc:\\Users\\seong\\anaconda3\\envs\\kst_pp\\lib\\site-packages\\requests\\models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32mc:\\Users\\seong\\anaconda3\\envs\\kst_pp\\lib\\site-packages\\urllib3\\response.py:1057\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[1;32m-> 1057\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[0;32m   1058\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1059\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\seong\\anaconda3\\envs\\kst_pp\\lib\\site-packages\\urllib3\\response.py:1206\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1203\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1205\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1206\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_chunk_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1208\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\seong\\anaconda3\\envs\\kst_pp\\lib\\site-packages\\urllib3\\response.py:1125\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1125\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m   1126\u001b[0m line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\seong\\anaconda3\\envs\\kst_pp\\lib\\socket.py:716\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    715\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 716\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    718\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "# 환경 변수 불러오기\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "uri = os.getenv(\"NEO4J_URI\")\n",
    "username = os.getenv(\"NEO4J_USERNAME\")\n",
    "password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "INDEX_NAME = \"index_name\"\n",
    "\n",
    "# Neo4j 데이터베이스 연결\n",
    "print(\"[INFO] Neo4j 드라이버 초기화 중...\")\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "try:\n",
    "    with driver.session() as session:\n",
    "        print(\"[INFO] Neo4j 연결 성공.\")\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Neo4j 연결 실패: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "\n",
    "# Custom OpenAI Embeddings\n",
    "class CustomOpenAIEmbeddings:\n",
    "    def __init__(self, api_key, model=\"text-embedding-ada-002\"):\n",
    "        openai.api_key = api_key\n",
    "        self.model = model\n",
    "\n",
    "    def embed_query(self, query):\n",
    "        print(f\"[INFO] OpenAI Embedding 생성 요청: {query}\")\n",
    "        try:\n",
    "            response = openai.Embedding.create(model=self.model, input=query)\n",
    "            embedding = response[\"data\"][0][\"embedding\"]\n",
    "            print(\"[INFO] Embedding 생성 성공.\")\n",
    "            return embedding\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Embedding 생성 실패: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "# Custom Embeddings 객체 생성\n",
    "embedder = CustomOpenAIEmbeddings(api_key=openai_api_key)\n",
    "\n",
    "\n",
    "# VectorRetriever 클래스 정의\n",
    "class VectorRetriever:\n",
    "    def __init__(self, driver, index_name, embedder):\n",
    "        self.driver = driver\n",
    "        self.index_name = index_name\n",
    "        self.embedder = embedder\n",
    "\n",
    "    def retrieve(self, query_text, top_k=5):\n",
    "        print(f\"[INFO] Query Embedding 생성 중: {query_text}\")\n",
    "        query_embedding = self.embedder.embed_query(query_text)\n",
    "        cypher_query = \"\"\"\n",
    "            MATCH (n:VectorNode)\n",
    "            WHERE n.vector IS NOT NULL\n",
    "            WITH n, n.vector AS node_vector, $query_vector AS query_vector\n",
    "            WITH n,\n",
    "            reduce(s = 0.0, i IN range(0, size(node_vector)-1) | s + node_vector[i] * query_vector[i]) AS dot_product,\n",
    "            reduce(s = 0.0, i IN range(0, size(node_vector)-1) | s + node_vector[i]^2) AS node_magnitude,\n",
    "            reduce(s = 0.0, i IN range(0, size(query_vector)-1) | s + query_vector[i]^2) AS query_magnitude\n",
    "            WITH n, dot_product / (sqrt(node_magnitude) * sqrt(query_magnitude)) AS similarity\n",
    "            WHERE similarity >= 0.5\n",
    "            RETURN n.name AS node_name, similarity\n",
    "            ORDER BY similarity DESC\n",
    "            LIMIT $top_k\n",
    "        \"\"\"\n",
    "        print(\"[INFO] Cypher 쿼리 실행 중...\")\n",
    "        results = []\n",
    "        try:\n",
    "            with self.driver.session() as session:\n",
    "                result = session.run(\n",
    "                    cypher_query, query_vector=query_embedding, top_k=top_k\n",
    "                )\n",
    "                results = [\n",
    "                    {\"node\": record[\"node_name\"], \"score\": record[\"similarity\"]}\n",
    "                    for record in result\n",
    "                ]\n",
    "                print(f\"[INFO] 쿼리 결과: {results}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Cypher 쿼리 실행 실패: {e}\")\n",
    "            return []\n",
    "        return results\n",
    "\n",
    "\n",
    "# Retriever 객체 생성\n",
    "retriever = VectorRetriever(driver, INDEX_NAME, embedder)\n",
    "\n",
    "\n",
    "# PromptTemplate 정의\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\"],\n",
    "    template=\"Please answer the question based on the context provided: {context}\",\n",
    ")\n",
    "\n",
    "# LangChain LLM (예시로 LLMChain 사용)\n",
    "llm = LLMChain(llm=ChatOllama(model=\"llama3:8b\"), prompt=prompt_template)\n",
    "\n",
    "\n",
    "class GraphRAG:\n",
    "    def __init__(self, retriever, llm):\n",
    "        self.retriever = retriever\n",
    "        self.llm = llm\n",
    "\n",
    "    def search(self, query_text, retriever_config):\n",
    "        print(\"[INFO] GraphRAG 검색 시작.\")\n",
    "        try:\n",
    "            results = self.retriever.retrieve(query_text, **retriever_config)\n",
    "            print(f\"[INFO] 검색된 유사 항목: {results}\")\n",
    "            context = \"\\n\".join([str(r[\"node\"]) for r in results])\n",
    "            llm_response = self.llm.invoke(input=query_text, context=context)\n",
    "            print(\"[INFO] LLM 응답 생성 성공.\")\n",
    "            return llm_response\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] GraphRAG 검색 실패: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "rag = GraphRAG(retriever=retriever, llm=llm)\n",
    "\n",
    "# 문제 처리 실행\n",
    "problem = \"기차에 사람이 $1500$ 명 타고 있었습니다. 이번 역에서 $80$ 명이 내리고 $124$ 명이 탔습니다. 지금 기차 안에 있는 사람은 모두 몇 명인지 구해 보세요.\"\n",
    "process_math_problem(problem)\n",
    "\n",
    "# Neo4j 드라이버 종료\n",
    "driver.close()\n",
    "print(\"[INFO] Neo4j 드라이버 종료 완료\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kst_pp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
