{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from neo4j import GraphDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "# 환경 변수에서 값 가져오기\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "uri = os.getenv(\"NEO4J_URI\")\n",
    "username = os.getenv(\"NEO4J_USERNAME\")\n",
    "password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "# Neo4j 데이터베이스 연결\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "session = driver.session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM을 사용한 수학 키워드 및 대분류 추출 함수\n",
    "def extract_keywords_and_category_from_math_problem(text):\n",
    "    prompt = (\n",
    "        \"다음 수학 문제에서 수학과 관련된 키워드와 가장 적합한 대분류를 추출하세요. \"\n",
    "        \"키워드는 '키워드:'로 시작하고 대분류는 '대분류:'로 시작하여 각각 추출해주세요. \"\n",
    "        \"대분류는 '변화와 관계', '도형과 측정', '자료와 가능성' 중에서 하나를 먼저 확인하고, \"\n",
    "        \"그래프나 표와 관련된 문제는 우선적으로 '자료와 가능성'으로 분류하고, \"\n",
    "        \"길이, 넓이, 들이, 무게 등의 단위 관련 문제는 '도형과 측정'으로 분류하며, \"\n",
    "        \"배열, 규칙, 비율과 관련된 문제는 '변화와 관계'로 분류하세요. \"\n",
    "        \"어디에도 속하지 않으면 '수와 연산'으로 분류하세요.\\n\"\n",
    "        f\"문제: {text}\"\n",
    "    )\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        max_tokens=150,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"].strip()\n",
    "\n",
    "\n",
    "# 키워드 전처리 함수\n",
    "def preprocess_keywords(raw_keywords):\n",
    "    # 키워드 부분만 추출\n",
    "    keywords = raw_keywords.split(\"키워드:\")[1].strip().split(\", \")\n",
    "    # 각 키워드를 소문자로 변환하여 리스트로 반환\n",
    "    return [kw.lower() for kw in keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자카드 유사도 계산 함수\n",
    "def jaccard_similarity(str1, str2):\n",
    "    set1 = set(str1)\n",
    "    set2 = set(str2)\n",
    "    return float(len(set1 & set2)) / len(set1 | set2)\n",
    "\n",
    "\n",
    "# 하위 노드만 찾는 함수\n",
    "def find_similar_leaf_nodes_from_graph(keywords, category):\n",
    "    query = \"\"\"\n",
    "    MATCH (c:Category {name: $category})-[:HAS_CHILD*]->(i:Item)\n",
    "    WHERE NOT (i)-[:HAS_CHILD]->()  // 최하위 노드만 선택\n",
    "    RETURN i.name AS item\n",
    "    \"\"\"\n",
    "    results = session.run(query, category=category)\n",
    "    leaf_nodes = [record[\"item\"].lower() for record in results]\n",
    "\n",
    "    matched_items = []\n",
    "\n",
    "    for item_name in leaf_nodes:\n",
    "        for keyword in keywords:\n",
    "            similarity = jaccard_similarity(keyword, item_name)\n",
    "            print(\n",
    "                f\"키워드 '{keyword}' vs 데이터베이스 항목 '{item_name}': 유사도 {similarity:.2f}\"\n",
    "            )  # 디버깅용\n",
    "            if similarity > 0.15:\n",
    "                matched_items.append(item_name)\n",
    "\n",
    "    return list(set(matched_items))  # 중복 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류 검증하는 LLM 함수\n",
    "def verify_classification_with_llm(classification, original_problem):\n",
    "    prompt = f\"수학 문제 '{original_problem}'이 분류 '{classification}'에 적합한지만 반환해주세요. '적합' 또는 '부적합'으로 대답해주세요.\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        max_tokens=50,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "    result = response.choices[0].message[\"content\"].strip()\n",
    "    print(f\"LLM 응답: {result}\")  # 응답 메시지 출력 (디버깅용)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 파이프라인 실행 함수\n",
    "def process_math_problem(problem):\n",
    "    # 1단계: 키워드 및 대분류 추출\n",
    "    raw_keywords_and_category = extract_keywords_and_category_from_math_problem(problem)\n",
    "    print(f\"추출된 키워드 및 대분류 (원본): {raw_keywords_and_category}\")\n",
    "\n",
    "    # 키워드와 대분류 분리\n",
    "    raw_keywords, most_similar_category = raw_keywords_and_category.split(\"\\n대분류: \")\n",
    "    keywords = preprocess_keywords(raw_keywords)\n",
    "    print(f\"전처리된 키워드: {keywords}\")\n",
    "    print(f\"가장 유사한 대분류: {most_similar_category}\")\n",
    "\n",
    "    # 2단계: 하위 노드에서 유사한 항목 찾기\n",
    "    matched_items = find_similar_leaf_nodes_from_graph(keywords, most_similar_category)\n",
    "    print(f\"찾은 하위 노드 항목: {matched_items}\")\n",
    "\n",
    "    # 3단계: 항목 검증\n",
    "    for item in matched_items:\n",
    "        verification = verify_classification_with_llm(item, problem)\n",
    "        print(f\"항목 '{item}' 검증 결과: {verification}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추출된 키워드 및 대분류 (원본): 키워드: ㉮와 ㉯ 상점, 판매한 우산 수, 그림그래프, 파란색 우산, 판매한 전체 우산 수의 차\n",
      "대분류: 자료와 가능성\n",
      "전처리된 키워드: ['㉮와 ㉯ 상점', '판매한 우산 수', '그림그래프', '파란색 우산', '판매한 전체 우산 수의 차']\n",
      "가장 유사한 대분류: 자료와 가능성\n",
      "키워드 '㉮와 ㉯ 상점' vs 데이터베이스 항목 '기준에 따른 결과 말하기': 유사도 0.07\n",
      "키워드 '판매한 우산 수' vs 데이터베이스 항목 '기준에 따른 결과 말하기': 유사도 0.06\n",
      "키워드 '그림그래프' vs 데이터베이스 항목 '기준에 따른 결과 말하기': 유사도 0.00\n",
      "키워드 '파란색 우산' vs 데이터베이스 항목 '기준에 따른 결과 말하기': 유사도 0.07\n",
      "키워드 '판매한 전체 우산 수의 차' vs 데이터베이스 항목 '기준에 따른 결과 말하기': 유사도 0.05\n",
      "키워드 '㉮와 ㉯ 상점' vs 데이터베이스 항목 '표로 나타내면 편리한 점 말하기': 유사도 0.11\n",
      "키워드 '판매한 우산 수' vs 데이터베이스 항목 '표로 나타내면 편리한 점 말하기': 유사도 0.11\n",
      "키워드 '그림그래프' vs 데이터베이스 항목 '표로 나타내면 편리한 점 말하기': 유사도 0.00\n",
      "키워드 '파란색 우산' vs 데이터베이스 항목 '표로 나타내면 편리한 점 말하기': 유사도 0.05\n",
      "키워드 '판매한 전체 우산 수의 차' vs 데이터베이스 항목 '표로 나타내면 편리한 점 말하기': 유사도 0.09\n",
      "키워드 '㉮와 ㉯ 상점' vs 데이터베이스 항목 '그래프로 나타내면 편리한 점 말하기': 유사도 0.10\n",
      "키워드 '판매한 우산 수' vs 데이터베이스 항목 '그래프로 나타내면 편리한 점 말하기': 유사도 0.10\n",
      "키워드 '그림그래프' vs 데이터베이스 항목 '그래프로 나타내면 편리한 점 말하기': 유사도 0.18\n",
      "키워드 '파란색 우산' vs 데이터베이스 항목 '그래프로 나타내면 편리한 점 말하기': 유사도 0.05\n",
      "키워드 '판매한 전체 우산 수의 차' vs 데이터베이스 항목 '그래프로 나타내면 편리한 점 말하기': 유사도 0.08\n",
      "키워드 '㉮와 ㉯ 상점' vs 데이터베이스 항목 '그림그래프로 나타내고 해석하기': 유사도 0.05\n",
      "키워드 '판매한 우산 수' vs 데이터베이스 항목 '그림그래프로 나타내고 해석하기': 유사도 0.05\n",
      "키워드 '그림그래프' vs 데이터베이스 항목 '그림그래프로 나타내고 해석하기': 유사도 0.29\n",
      "키워드 '파란색 우산' vs 데이터베이스 항목 '그림그래프로 나타내고 해석하기': 유사도 0.05\n",
      "키워드 '판매한 전체 우산 수의 차' vs 데이터베이스 항목 '그림그래프로 나타내고 해석하기': 유사도 0.04\n",
      "키워드 '㉮와 ㉯ 상점' vs 데이터베이스 항목 '막대그래프로 나타내고 해석하기': 유사도 0.05\n",
      "키워드 '판매한 우산 수' vs 데이터베이스 항목 '막대그래프로 나타내고 해석하기': 유사도 0.05\n",
      "키워드 '그림그래프' vs 데이터베이스 항목 '막대그래프로 나타내고 해석하기': 유사도 0.19\n",
      "키워드 '파란색 우산' vs 데이터베이스 항목 '막대그래프로 나타내고 해석하기': 유사도 0.05\n",
      "키워드 '판매한 전체 우산 수의 차' vs 데이터베이스 항목 '막대그래프로 나타내고 해석하기': 유사도 0.04\n",
      "키워드 '㉮와 ㉯ 상점' vs 데이터베이스 항목 '꺾은선그래프로 나타내고 해석하기': 유사도 0.05\n",
      "키워드 '판매한 우산 수' vs 데이터베이스 항목 '꺾은선그래프로 나타내고 해석하기': 유사도 0.05\n",
      "키워드 '그림그래프' vs 데이터베이스 항목 '꺾은선그래프로 나타내고 해석하기': 유사도 0.18\n",
      "키워드 '파란색 우산' vs 데이터베이스 항목 '꺾은선그래프로 나타내고 해석하기': 유사도 0.05\n",
      "키워드 '판매한 전체 우산 수의 차' vs 데이터베이스 항목 '꺾은선그래프로 나타내고 해석하기': 유사도 0.04\n",
      "키워드 '㉮와 ㉯ 상점' vs 데이터베이스 항목 '띠그래프로 나타내고 해석하기': 유사도 0.05\n",
      "키워드 '판매한 우산 수' vs 데이터베이스 항목 '띠그래프로 나타내고 해석하기': 유사도 0.05\n",
      "키워드 '그림그래프' vs 데이터베이스 항목 '띠그래프로 나타내고 해석하기': 유사도 0.20\n",
      "키워드 '파란색 우산' vs 데이터베이스 항목 '띠그래프로 나타내고 해석하기': 유사도 0.05\n",
      "키워드 '판매한 전체 우산 수의 차' vs 데이터베이스 항목 '띠그래프로 나타내고 해석하기': 유사도 0.04\n",
      "키워드 '㉮와 ㉯ 상점' vs 데이터베이스 항목 '원그래프로 나타내고 해석하기': 유사도 0.05\n",
      "키워드 '판매한 우산 수' vs 데이터베이스 항목 '원그래프로 나타내고 해석하기': 유사도 0.05\n",
      "키워드 '그림그래프' vs 데이터베이스 항목 '원그래프로 나타내고 해석하기': 유사도 0.20\n",
      "키워드 '파란색 우산' vs 데이터베이스 항목 '원그래프로 나타내고 해석하기': 유사도 0.05\n",
      "키워드 '판매한 전체 우산 수의 차' vs 데이터베이스 항목 '원그래프로 나타내고 해석하기': 유사도 0.04\n",
      "키워드 '㉮와 ㉯ 상점' vs 데이터베이스 항목 '평균 구하고 해석하기': 유사도 0.07\n",
      "키워드 '판매한 우산 수' vs 데이터베이스 항목 '평균 구하고 해석하기': 유사도 0.07\n",
      "키워드 '그림그래프' vs 데이터베이스 항목 '평균 구하고 해석하기': 유사도 0.00\n",
      "키워드 '파란색 우산' vs 데이터베이스 항목 '평균 구하고 해석하기': 유사도 0.07\n",
      "키워드 '판매한 전체 우산 수의 차' vs 데이터베이스 항목 '평균 구하고 해석하기': 유사도 0.05\n",
      "키워드 '㉮와 ㉯ 상점' vs 데이터베이스 항목 '가능성을 말로 표현하고 비교하기': 유사도 0.05\n",
      "키워드 '판매한 우산 수' vs 데이터베이스 항목 '가능성을 말로 표현하고 비교하기': 유사도 0.05\n",
      "키워드 '그림그래프' vs 데이터베이스 항목 '가능성을 말로 표현하고 비교하기': 유사도 0.00\n",
      "키워드 '파란색 우산' vs 데이터베이스 항목 '가능성을 말로 표현하고 비교하기': 유사도 0.05\n",
      "키워드 '판매한 전체 우산 수의 차' vs 데이터베이스 항목 '가능성을 말로 표현하고 비교하기': 유사도 0.04\n",
      "키워드 '㉮와 ㉯ 상점' vs 데이터베이스 항목 '가능성을 수로 표현하기': 유사도 0.06\n",
      "키워드 '판매한 우산 수' vs 데이터베이스 항목 '가능성을 수로 표현하기': 유사도 0.12\n",
      "키워드 '그림그래프' vs 데이터베이스 항목 '가능성을 수로 표현하기': 유사도 0.00\n",
      "키워드 '파란색 우산' vs 데이터베이스 항목 '가능성을 수로 표현하기': 유사도 0.06\n",
      "키워드 '판매한 전체 우산 수의 차' vs 데이터베이스 항목 '가능성을 수로 표현하기': 유사도 0.10\n",
      "키워드 '㉮와 ㉯ 상점' vs 데이터베이스 항목 '가능성을 예상하고 적절한 판단 내리기': 유사도 0.10\n",
      "키워드 '판매한 우산 수' vs 데이터베이스 항목 '가능성을 예상하고 적절한 판단 내리기': 유사도 0.14\n",
      "키워드 '그림그래프' vs 데이터베이스 항목 '가능성을 예상하고 적절한 판단 내리기': 유사도 0.00\n",
      "키워드 '파란색 우산' vs 데이터베이스 항목 '가능성을 예상하고 적절한 판단 내리기': 유사도 0.05\n",
      "키워드 '판매한 전체 우산 수의 차' vs 데이터베이스 항목 '가능성을 예상하고 적절한 판단 내리기': 유사도 0.12\n",
      "찾은 하위 노드 항목: ['원그래프로 나타내고 해석하기', '막대그래프로 나타내고 해석하기', '그래프로 나타내면 편리한 점 말하기', '그림그래프로 나타내고 해석하기', '꺾은선그래프로 나타내고 해석하기', '띠그래프로 나타내고 해석하기']\n",
      "LLM 응답: 적합\n",
      "항목 '원그래프로 나타내고 해석하기' 검증 결과: 적합\n",
      "LLM 응답: 적합\n",
      "항목 '막대그래프로 나타내고 해석하기' 검증 결과: 적합\n",
      "LLM 응답: 적합\n",
      "항목 '그래프로 나타내면 편리한 점 말하기' 검증 결과: 적합\n",
      "LLM 응답: 적합\n",
      "항목 '그림그래프로 나타내고 해석하기' 검증 결과: 적합\n",
      "LLM 응답: 부적합\n",
      "항목 '꺾은선그래프로 나타내고 해석하기' 검증 결과: 부적합\n",
      "LLM 응답: 적합\n",
      "항목 '띠그래프로 나타내고 해석하기' 검증 결과: 적합\n"
     ]
    }
   ],
   "source": [
    "# 예시 수학 문제\n",
    "problem = \"㉮와 ㉯ 상점에서 하루에 판매한 우산 수를 각각 조사하여 나타낸 그림그래프입니다. 판매한 파란색 우산 수는 ㉯ 상점이 ㉮ 상점보다  $3$ 개,  $4$ 개 더 많을 때 두 상점에서 하루에 판매한 전체 우산 수의 차는 몇 개인지 구해 보세요.\"\n",
    "process_math_problem(problem)\n",
    "\n",
    "# Neo4j 세션 종료\n",
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kst_pp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
