{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping empty file: ./images/training/y\\elementary3\\P3_1_03_25885_160996.json\n",
      "figure_text가 있는 파일의 수: 1964\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "def count_files_with_figure_text(base_directory):\n",
    "    count = 0\n",
    "    # elementary3부터 elementary6까지 디렉토리 탐색\n",
    "    for grade in range(3, 7):  # 3에서 6까지\n",
    "        directory = os.path.join(base_directory, f\"elementary{grade}\")\n",
    "        if os.path.isdir(directory):\n",
    "            for filename in os.listdir(directory):\n",
    "                if filename.endswith(\".json\"):\n",
    "                    file_path = os.path.join(directory, filename)\n",
    "                    # BOM을 자동으로 처리하기 위해 utf-8-sig로 파일을 엽니다.\n",
    "                    try:\n",
    "                        with open(file_path, \"r\", encoding=\"utf-8-sig\") as file:\n",
    "                            file_content = (\n",
    "                                file.read().strip()\n",
    "                            )  # 파일 내용 읽기 및 공백 제거\n",
    "\n",
    "                            # 빈 파일은 건너뛰기\n",
    "                            if not file_content:\n",
    "                                print(f\"Skipping empty file: {file_path}\")\n",
    "                                continue\n",
    "\n",
    "                            data = json.loads(\n",
    "                                file_content\n",
    "                            )  # json.loads로 로드하여 오류 확인\n",
    "\n",
    "                            # OCR_info에 figure_text가 존재하고, null이 아닌 항목이 있는지 확인\n",
    "                            if any(\n",
    "                                item.get(\"figure_text\") not in [None, \"null\", \"\"]\n",
    "                                for item in data.get(\"OCR_info\", [])\n",
    "                            ):\n",
    "                                count += 1\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"Error decoding JSON in file: {file_path} - {e}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading file {file_path}: {e}\")\n",
    "    return count\n",
    "\n",
    "\n",
    "# base_directory 설정\n",
    "base_directory = \"./images/training/y\"\n",
    "result = count_files_with_figure_text(base_directory)\n",
    "print(f\"figure_text가 있는 파일의 수: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from transformers import AutoProcessor, AutoModel\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# KoCLIP 모델과 프로세서 로드\n",
    "processor = AutoProcessor.from_pretrained(\"koclip/koclip-base-pt\")\n",
    "model = AutoModel.from_pretrained(\"koclip/koclip-base-pt\")\n",
    "\n",
    "# 텍스트 옵션\n",
    "text_options = [\"지도\", \"도형\", \"그래프\", \"표\"]\n",
    "\n",
    "\n",
    "def predict_image_text_relation(image_path, text_options):\n",
    "    # 이미지 파일 열기\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # 이미지 전처리 및 텍스트 전처리 (모델에 입력할 수 있도록 변환)\n",
    "    inputs = processor(\n",
    "        images=image, text=text_options, return_tensors=\"pt\", padding=True\n",
    "    )\n",
    "\n",
    "    # 모델을 통해 이미지와 텍스트 간의 임베딩을 추출\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # 이미지와 텍스트 간의 유사도 (logits_per_image)\n",
    "    logits_per_image = outputs.logits_per_image\n",
    "\n",
    "    # 유사도 점수 중 가장 높은 값을 가진 텍스트 찾기\n",
    "    similarity_scores = logits_per_image.squeeze()  # 배치 차원 제거\n",
    "    max_similarity_idx = torch.argmax(similarity_scores).item()\n",
    "    max_similarity_score = similarity_scores[max_similarity_idx].item()\n",
    "\n",
    "    # 임계값 설정 (유사도 점수가 충분히 높은 경우에만 출력)\n",
    "    threshold = 0.7  # 필요에 따라 조정 가능\n",
    "    if max_similarity_score >= threshold:\n",
    "        print(f\"이미지와 가장 유사한 텍스트: '{text_options[max_similarity_idx]}'\")\n",
    "        print(f\"유사도 점수: {max_similarity_score:.4f}\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\n",
    "            f\"이미지가 지정된 텍스트와 충분히 유사하지 않습니다. 유사도 점수: {max_similarity_score:.4f}\"\n",
    "        )\n",
    "        return False\n",
    "\n",
    "\n",
    "def process_json_files(json_dir):\n",
    "    # figure_text가 있는 파일들을 찾아서 처리\n",
    "    figure_text_files = []\n",
    "\n",
    "    # 디렉토리 내의 모든 JSON 파일 검사\n",
    "    for root, _, files in os.walk(json_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".json\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    with open(file_path, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "                        data = json.load(f)\n",
    "                        # figure_text가 있는 경우만 필터링\n",
    "                        for item in data.get(\"OCR_info\", []):\n",
    "                            if item.get(\"figure_text\"):\n",
    "                                figure_text_files.append(data[\"question_filename\"])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "    return figure_text_files\n",
    "\n",
    "\n",
    "# 폴더 내 JSON 파일들이 있는 디렉토리 경로 지정 (y 폴더)\n",
    "json_base_dir = \"./images/training/y\"\n",
    "\n",
    "# x 폴더 내 이미지 파일 경로\n",
    "image_base_dir = \"./images/training/x\"\n",
    "\n",
    "# figure_text가 있는 파일들의 이름 가져오기 (elementary3부터 elementary6까지)\n",
    "for i in range(3, 7):\n",
    "    json_dir = os.path.join(json_base_dir, f\"elementary{i}\")\n",
    "\n",
    "    # figure_text가 있는 파일들의 이름 가져오기\n",
    "    figure_text_files = process_json_files(json_dir)\n",
    "\n",
    "    # 가져온 이미지 파일들을 처리\n",
    "    for filename in figure_text_files:\n",
    "        image_path = os.path.join(image_base_dir, f\"elementary{i}\", filename)\n",
    "        print(f\"Processing image: {image_path}\")\n",
    "        if predict_image_text_relation(image_path, text_options):\n",
    "            print(f\"유효한 이미지로 처리 완료: {image_path}\")\n",
    "        else:\n",
    "            print(f\"유효하지 않은 이미지로 제외: {image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Caption: a diagram showing the area of a circle\n"
     ]
    }
   ],
   "source": [
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "\n",
    "# BLIP 모델과 프로세서 로드\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\n",
    "    \"Salesforce/blip-image-captioning-base\"\n",
    ")\n",
    "\n",
    "\n",
    "def generate_caption(image_path):\n",
    "    # 이미지 파일 열기\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # 이미지 전처리 및 모델 입력 준비\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "    # 모델을 통해 이미지에 대한 캡션 생성\n",
    "    out = model.generate(**inputs)\n",
    "\n",
    "    # 생성된 캡션 디코딩\n",
    "    caption = processor.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "    print(f\"Generated Caption: {caption}\")\n",
    "\n",
    "\n",
    "# 테스트할 이미지 파일 경로 지정\n",
    "image_path = \"./images/training/x/elementary3/P3_2_03_39052_153966.png\"\n",
    "generate_caption(image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kst_pp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
